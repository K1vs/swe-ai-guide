### 3. Базовий сценарій взаємодії з LLM через чат

LLM - це не субʼєкт мислення, а потужний статистичний предиктор наступного токена. Звідси - якість відповіді значно сильніше залежить від формулювання і контексту вводу, ніж у звичній міжлюдській комунікації.

Базова взаємодія виглядає так:
- користувач формулює промт (інструкції, питання, приклади) й передає його разом із контекстом діалогу;
- модель послідовно передбачає наступні токени, формуючи відповідь;
- історія чату накопичує контекст, тому релевантність і чіткість вводу критичні для результату.

Ввід у LLM прийнято називати "промт", а техніки побудови ефективних промтів - "промт‑інженерія". Вони зʼявилися як відповідь на високу чутливість моделей до формулювань і структури запиту.

Ось список практично ефективних методів промтингу на сьогодні, якими я регулярно користуюсь:
1. Задавайте ШІ роль. Copilot (чи подібний інструмент) уже робить це, задаючи роль розробника, але ви можете уточнити її мовою, фреймворком та додатковими технологіями. Дуже важливо уточнити, що він має створювати production-ready код (готовий до продакшену - з обробкою помилок, логуванням, документацією). 

   Приклади ролей:
   - "Ти senior .NET розробник з 10+ років досвіду. Пиши production-ready код з обробкою помилок та логуванням."
   - "Ти QA engineer. Склади план тестування для цього API, враховуючи крайові випадки."
   - "Ти security expert. Проаналізуй цей код на вразливості та запропонуй покращення."

2. Явно вказуйте необхідність створити план перед виконанням задачі: "Створи план, за потреби розбий його на підпункти; для кожного пункту - вкажи причину та наслідок, перевір причинно-наслідкові зв’язки, упевнись, що план здатний виконати задачу і не спричинить побічних ефектів".

3. Для складних задач спочатку просіть зробити лише план і зупинитися. Якщо план вийшов невдалим - зупиніть роботу й опишіть проблеми. Для великих задач просіть зберегти глобальний план в окремий .md-файл і позначати виконані кроки - це допоможе освіжати контекст, не втрачаючи прогрес, і робити проміжні коміти.

4. Якщо задача стикується з великим кодом - просіть дослідити лінію стику, визначити, чи потрібен рефакторинг, і, якщо так, - додати необхідні кроки на початок плану.

5. При проєктуванні рішень іноді корисно генерувати альтернативні гілки плану, порівнювати їх, критикувати, обирати найкращі, відкидати тупикові й повертатися назад.

6. Для перевірки рішень просіть ШІ навести контрприклад або сценарій, де запропонований підхід може не спрацювати. Наприклад: "За яких умов цей алгоритм буде неефективним?" або "Які крайові випадки можуть спричинити проблеми?". Це допомагає виявити слабкі місця на етапі планування.

7. Оцінюйте рішення за критеріями: maintainability, scalability, reusability, security, performance тощо. Не все одразу - обирайте 3–4 найбільш важливих для поточної задачі. Можна також задати пріоритетність.

8. Для боротьби з галюцинаціями іноді корисно просити вказувати рівень упевненості від 1 до 10 при створенні плану. Це зменшує кількість вигадок і дає точки для додаткової перевірки.

9. Найкраща структура запиту:
- Контекст (про що мова)
- Задача (що треба зробити)  
- Примітки (стратегія, на що звернути увагу, що бажано, що небажано тощо)

   Приклад:
   ```
   **Контекст:** Маю ASP.NET Core Web API з авторизацією через JWT токени. 
   Сервіс UserService має метод GetUserById(), який повертає null для неіснуючих користувачів.
   
   **Задача:** Створи endpoint GET /api/users/{id}, який повертає дані користувача або 404.
   
   **Примітки:** 
   - Використовуй стандартні HTTP статус коди
   - Додай логування на рівні Information
   - Метод має бути async  
   - Не використовуй magic strings для логів
   ```
   
   Інколи доцільно міняти порядок, особливо якщо якась примітка вперто ігнорується.

10. Дещо простіше зробити вручну. Якщо бачите, що ШІ “застряг”, зупиніть його та допоможіть, описавши, як саме ви це зробили. Далі він зможе підхопити й адаптувати.

11. З ШІ добре працює TDD-підхід. Можна явно вказати це в задачі по генерації плану: спочатку робимо порожні контракти, далі пишемо тести, і тільки потім код. Усі ці дії мають бути в різних пунктах плану. Це фактично дає ще один проміжний етап: текстовий план → контракти + тести → реалізація. Додатковий етап - це додатковий шанс на вчасну інтервенцію і корекцію відхилення, яке у LLM катастрофічно наростає.

12. Просіть підтверджувати рішення посиланнями, наприклад, для рішень, які ґрунтуються на фактах щодо технологій чи бібліотек, вимагайте посилання на ці факти. Навіть якщо ви їх не прочитаєте, це іноді може вберегти від галюцинацій.

Багато правил промтингу, що були критичними для ранніх LLM, нині або менш важливі, або вже вбудовані в самі моделі. До того ж, чимало інструментів роботи з ШІ автоматично застосовують системні промти та інші налаштування під капотом.

Втім, навички побудови правильних промтів залишаються корисними у складних, нетривіальних і доменно‑специфічних випадках, коли потрібна керованість, відтворюваність і точність.

### Джерела й подальше читання

- [Prompt Engineering Guide](https://www.promptingguide.ai) - DAIR‑AI, постійно оновлюється.
- [Prompt engineering best practices](https://platform.openai.com/docs/guides/prompt-engineering) - OpenAI, гайд.
- [Prompt engineering overview](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview) - Anthropic, огляд.
- [Prompt Engineering](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/) - L. Weng, 2023.
- [Chain‑of‑Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903) - J. Wei та ін., 2022.
- [Self‑Consistency Improves Chain of Thought Reasoning in Large Language Models](https://arxiv.org/abs/2203.11171) - X. Wang та ін., 2022.
- [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629) - S. Yao та ін., 2022.
- [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601) - S. Yao та ін., 2023.
- [Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning](https://arxiv.org/abs/2211.12588) - X. Lei та ін., 2022.
- [Pre‑train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing](https://arxiv.org/abs/2107.13586) - P. Liu та ін., 2023.