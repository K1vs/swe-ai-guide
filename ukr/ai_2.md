## 2. Базові ідеї сучасних мовних моделей

### Історичний контекст і базові поняття
Нейромережі були створені як спосіб навчити машину апроксимувати складні залежності у даних. Найпростіший елемент - перцептрон - бере вхідні ознаки, зважує їх, додає зсув і перевіряє, чи перетнув поріг. Один перцептрон дає лише лінійне розділення, але багатошаровий перцептрон (MLP) з нелінійностями здатен апроксимувати майже будь-яку функцію. 

Ваги підбираються автоматично зворотним поширенням помилки: мережа порівнює прогноз із правильним значенням і крок за кроком регулює параметри у напрямку зменшення втрат.

Мова вимагає додаткового кроку - перетворення тексту на числа. Для цього існує токенізація: текст ділиться на токени, найчастіше - на субслова (BPE, WordPiece, Unigram - алгоритми, що розбивають слова на частини типу префікс корінь суфікс закінчення, наприклад "програм-уванн-я"), що робить систему стійкою до рідкісних або нових слів. Далі токени проектуються у багатовимірні вектори (вбудовування). Семантична інтуїція проста: близькі за значенням слова мають близькі вектори; геометрія простору кодує подібність і асоціації.

Довгий час панували рекурентні мережі (RNN) і їхні варіанти LSTM/GRU. Вони читали послідовність по одному токену, підтримуючи прихований стан як "пам'ять". На практиці це часто ламалося на далеких залежностях (зникання або вибух градієнтів), а головне - обчислення були послідовними й погано масштабувалися на сучасне апаратне забезпечення. Саме тут трансформери запропонували новий шлях.

### Фундаментальні принципи трансформерів
Передусім, трансформер - це модель автодоповнення: маючи на вході послідовність токенів, вона оцінює розподіл імовірностей для наступного токена й обирає найбільш імовірний. Потім цей вгаданий токен додається в кінець послідовності, і процес повторюється крок за кроком, доки не отримаємо завершений результат. А як саме вона вгадує наступний токен, пояснимо спочатку простими словами. Ключем успіху цього підходу є механізм уваги (attention), який дозволяє моделі вибірково зосереджуватися на релевантних фрагментах контексту.

Кожне слово в реченні перед новим кроком дивиться на всі інші й вирішує, кого і наскільки врахувати. Слово формулює своє "запитання": що мені зараз важливо? Це і є запит (Q). Кожне інше слово має "ярличок", який каже, про що воно - ключ (K). І має "вміст", який воно може додати - значення (V). Увага обчислює ваги "наскільки" між запитанням поточного слова й ярличками інших, а потім змішує їхній вміст пропорційно цим вагам. Результат - нове подання слова, яке врахувало релевантний контекст.

Простий приклад без формул. "Іван купив апельсини. Вони були стиглі." Для слова "Вони" найкорисніше - дивитися на "апельсини", тож вага уваги до "апельсини" буде найбільшою; до "Іван" - меншою; до службових слів - ще меншою. Нове подання токена "Вони" стає зваженою сумішшю вмістів інших слів, де "вміст" - це те, що слово може "передати" (значення, V).

Звідси випливають компоненти й розмірності (коротко і на прикладі). Маємо матрицю подань токенів X розміру n×d_model (n - довжина послідовності, d_model - розмір векторного подання токена, типово 512-4096 чисел, "ширина" шару). 

Для простоти візьмемо одну "голову" уваги з розмірністю d_head (це "ширина" підпростору однієї голови: скільки чисел містить вектор Q/K/V для цієї голови, типово 64-128). Голова уваги - це окремий "канал" уваги з власними матрицями ваг W_Q, W_K, W_V (кожна розміру d_model×d_head для цієї голови) - це параметри, які модель вивчає під час навчання. Така голова "ловить" свій тип залежностей. 

Це можна записати таким чином для однієї голови уваги:

$$
A = \mathrm{softmax}\!\left(\frac{QK^{\top}}{\sqrt{d_{head}}}\right),\quad \text{out} = A\,V.
$$

Добуток QK^T дає "схожості" між запитами і ключами: наскільки моє "що мені потрібно?" збігається з "про що ти?". Ділення на √d_head просто тримає числа в адекватному масштабі, щоб softmax не затирав дрібні відмінності. Softmax по рядках перетворює схожості на ваги від 0 до 1, що в сумі дають 1 - тобто "скільки довіри" виділяємо кожному слову. Помноживши A на V, беремо зважену суміш їхнього вмісту - отримуємо те саме "врахований контекст". 

У багатоголовій увазі кілька голів працюють паралельно в різних підпросторах, їхні виходи конкатенуються і пропускаються через вихідну лінійну проєкцію W_O (розміру H·d_head×d_model), що повертає розмірність назад до d_model. Далі додається залишковий зв'язок і нормалізація шару, після чого результат проходить через невеликий MLP (багатошаровий перцептрон - звичайна нейромережа з кількома шарами) і знову отримує залишковий зв'язок з нормалізацією. На виході останнього шару подання проєктують у розмір словника і через softmax отримують розподіл імовірностей наступного токена.

Ключова перевага трансформера - повна паралелізація по токенах під час навчання: послідовність не треба опрацьовувати крок за кроком, можна одразу співставити все з усім. Це покращує моделювання довгих залежностей і відкриває двері до ефективного масштабування. Емпіричні закони показують, що якість систематично зростає із збільшенням параметрів, даних і обчислень за правильних пропорцій. На практиці це реалізують через різні форми паралелізму (data/model/pipeline/tensor - способи розділити навчання між GPU), змішену точність (FP16/BF16 - 16-бітні числа замість 32-бітних для швидкості), шардінг оптимізатора і чекпойнтинг. Водночас ретельна підготовка даних і баланс корпусів часто не менш важливі, ніж додаткові FLOPs (операції з плаваючою комою - міра обчислювальної потужності).

Вартість самоуваги зростає квадратично зі збільшенням довжини контексту: удвічі довше вікно - приблизно вчетверо більше обчислень і пам’яті. Тому розширення контексту потребує інженерних прийомів: від відносних позиційних кодувань і буферизації до спарс- або локальної уваги. У прикладних системах це доповнюють зовнішнім пошуком знань (RAG - Retrieval-Augmented Generation, пошук інформації в базах даних + генерація) і кешуванням, аби не тягнути в модель усе одразу.

### Недоліки та перспективи подальшого розвитку
Попри проривні можливості роботи з мовою, LLM мають системні обмеження. Вони схильні до "галюцинацій" - упевненої генерації неправди у зонах невизначеності; чутливі до формулювань підказок; не мають вбудованої перевірки фактів. Найбільш відчутним є дефіцит справжньої довготривалої пам'яті: все, що виходить за межі вікна контексту, втрачається, тож модель не "пам'ятає" користувача чи довгий процес у строгому сенсі. Також мають значення вартість і енергоспоживання, упередження, питання безпеки й конфіденційності, обмежене планування та міркування без допоміжних інструментів.

Перспективні напрями - інтеграція зовнішньої пам’яті та індексів знань (RAG, персональні сховища), нові схеми уваги з меншою складністю, стиснення і рекурентні механізми пам’яті на довгій дистанції, більш надійні методи валідації тверджень (перевірка джерел, самооцінка впевненості). Критично важливим є постдеплойне навчання: безпечні контури continual learning, онлайн-оновлення знань та керований RLHF (навчання з підкріпленням на основі людських оцінок) у продуктиві. Додатково активно розвивається інтеграція з інструментами й агентами, що дозволяють моделі діяти у світі, а не лише генерувати текст.

### Підсумок
Трансформерні LLM - це технологічний прорив, співмірний із появою ЕОМ чи Інтернету. Вони навчилися бачити дальні залежності, масштабуватися на кластери й працювати з мовою так, як здавалося неможливим зовсім недавно. Та цей крок, найімовірніше, не останній на шляху до реального AGI (штучного загального інтелекту). Щоб перейти від "великого автодоповнення" до широкої розумової здатності, нам потрібні справжня довготривала пам’ять, безпечне постдеплойне навчання і нові індуктивні упередження для надійного планування та міркування. Прорив уже стався; тепер - черга наступних.

### Джерела й подальше читання

- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) - A. Vaswani та ін., 2017.
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) - J. Alammar, 2018.
- [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) - T. Brown та ін., 2020.
- [Scaling Laws for Neural Language Models](https://arxiv.org/abs/2001.08361) - J. Kaplan та ін., 2020.
- [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) - J. Hoffmann та ін., 2022.
- [SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing](https://arxiv.org/abs/1808.06226) - T. Kudo, J. Richardson, 2018.
- [Neural Machine Translation of Rare Words with Subword Units](https://arxiv.org/abs/1508.07909) - R. Sennrich, B. Haddow, A. Birch, 2016.
- [Efficient Transformers: A Survey](https://arxiv.org/abs/2009.06732) - Y. Tay, M. Dehghani, D. Bahri, 2020.
- [Retrieval-Augmented Generation for Knowledge-Intensive NLP](https://arxiv.org/abs/2005.11401) - P. Lewis та ін., 2020.
- [Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155) - L. Ouyang та ін., 2022.
- [Constitutional AI: Harmlessness from AI Feedback](https://arxiv.org/abs/2212.08073) - Y. Bai та ін., 2022.
- [3Blue1Brown: Neural network](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) - 3Blue1Brown цикл відео про нейромережі