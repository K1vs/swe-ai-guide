### 7. Впровадження ШІ у процеси розробки

ШІ у найближчі роки суттєво змінить звичні процеси та методології розробки ПЗ. Водночас поки немає чіткої "карти" того, що і як саме потрібно змінювати, а постійне розширення можливостей моделей додає невизначеності. Це не має зупиняти впровадження: варто починати з точкових інтеграцій у тих місцях існуючих процесів, де ШІ вже сьогодні дає відчутний приріст швидкості та якості.

#### Безпека використання ШІ в корпоративній розробці

Головне правило: для будь‑яких службових задач користуйся тільки корпоративними ліцензіями та акаунтами затверджених ШІ‑інструментів; персональні чи безкоштовні акаунти для роботи з кодом і даними компанії - заборонені. Це забезпечує enterprise‑приватність: ізоляцію даних, відсутність тренування на вашому контенті, аудит, SSO/SAML і контроль доступів. Решта - здоровий глузд: не вставляй секрети/PII у промпти та мінімізуй обсяг контексту, який відправляєш у модель.

Окремою опцією зниження ризиків є локальне розгортання LLM. Наприклад, моделі на кшталт Gemma 3 можна запускати через Ollama або LM Studio, залишаючи дані всередині інфраструктури. Це значно зменшує імовірність витоків, але потребує апаратних ресурсів та певної ML‑експертизи, а результати зазвичай скромніші за флагманські хмарні моделі.

Існує й менш імовірний, але реальний ризик ліцензійної несумісності: LLM може згенерувати фрагменти коду, чия ліцензія не узгоджується з політиками компанії. Захист від таких ситуацій - це надійність провайдера та обережне використання LLM для генерації аналогів комерційних алгоритмів.

#### Інструменти для розробників

GitHub Copilot у нових версіях виходить далеко за межі автодоповнення: це фактично агент, який розуміє контекст робочої області, допомагає працювати з PR та Issue, генерує тести, пояснює код, навігує проєктом і виконує команди. Він доступний у більшості популярних IDE - від VS Code і JetBrains до Visual Studio. У корпоративному середовищі Copilot купують у межах організацій GitHub; якщо інструмент оформлений в одній організації, а репозиторії знаходяться в іншій або поза GitHub, частина можливостей може бути обмежена політиками доступу та інтеграції.

Cursor - окрема IDE, спеціально спроєктована для агентно‑асистованої розробки. Вона глибоко працює з робочою текою, дозволяючи вести "розмовні" edits і запускати типові задачі у фоні завдяки асинхронним агентам. Оскільки Cursor є форком VS Code, не всі розширення сумісні: автори пропонують власні альтернативи для найпопулярніших плагінів, але інколи цього недостатньо за потужністю чи зручністю.

Windsurf еволюціонував із розширення в повноцінну IDE, з урахуванням потреб ШІ‑асистованої розробки. Результати часто подібні до Cursor, однак підхід має кілька особливостей: наявні власні легкі моделі для тривіальних задач (вони швидкі, хоча менш потужні), а також обмежені плагіни для інших IDE. Окремість імплементації IDE робить середовище швидким і легким, але іноді бракує потрібних функцій; перед впровадженням варто перевірити підтримку вашого стеку, розширення частково пом’якшують проблему, але не усувають її повністю.

#### Доступ до API моделей

Доступ через Copilot, Cursor чи Windsurf не надає "вільних" API‑ключів до моделей. Якщо потрібна інтеграція у внутрішні сервіси або бекенди, API купують окремо - напряму у провайдерів на кшталт OpenAI, Google чи Anthropic (Claude) або через агрегатори на зразок OpenRouter, які під одним контрактом відкривають доступ до різних моделей.

API‑ключі корисні розробнику для побудови власних агентів і RAG‑систем, створення внутрішніх інструментів та ботів, інтеграції перевірок у CI, а також для напівавтоматизованих міграцій і рефакторингу. Для швидкого старту можна використати AnythingLLM як коробковий RAG. Для напівмануального тестування користувацьких інтерфейсів стане у пригоді BrowserUse - агент, який уміє керувати браузером за текстовими інструкціями й потребує доступу до LLM. Якщо інфраструктура розгортається у хмарі, Azure AI Foundry та AWS Bedrock дозволяють підключати зовнішні ключі або купувати моделі безпосередньо, надаючи керування доступами, моніторинг і білінг на рівні підприємства.

#### ШІ для роботи з вимогами та тікетами

У продуктах Atlassian корисним є Rovo - вбудований асистент у Jira та Confluence, який допомагає шукати, узагальнювати й генерувати вміст. Дістатися до Jira/Confluence можна також через розширення або MCP‑сервери з боку Copilot чи агентних IDE на кшталт Cursor. На практиці LLM добре економить час під час роботи з вимогами: стисло підсумовує епіки та тікети, витягує факти й ризики, пропонує зв’язки між задачами та виявляє дублікати. Він може сформувати acceptance‑criteria, контрольні списки і базові сценарії тестування, а також пришвидшити грумінг - від розбиття епіка та оцінки складності до уточнення формулювань. Після завершення робіт LLM здатен допомогти з нотатками релізів і короткими статус‑оновленнями на базі PR і комітів.

#### Транскрибування та сумаризація зустрічей

Транскрибування дає повний текст зустрічі, але головна практична цінність - саме сумаризація: швидке виділення ключових рішень, екшн‑айтемів, ризиків і відкритих питань. Як приклад, Fireflies інтегрується з календарями та системами відеоконференцій і надає API, через які нотатки можна автоматично завантажувати у внутрішні інструменти.

#### Джерела про ризики витоків і безпеку

- [OWASP Top 10 for LLM Applications](https://owasp.org/www-project-top-10-for-large-language-model-applications/) - ключові загрози (інʼєкції промптів, витоки, ескалація доступів) та рекомендації захисту.
- [NIST AI Risk Management Framework 1.0](https://www.nist.gov/itl/ai-risk-management-framework) - рамка керування ризиками ШІ, включно з приватністю та безпекою.
- [NCSC (UK): Guidelines for secure AI system development](https://www.ncsc.gov.uk/files/Guidelines-for-secure-AI-system-development.pdf) - рекомендації щодо розробки безпечних систем штучного інтелекту.
- [OpenAI: API data usage policies](https://openai.com/policies/api-data-usage-policies) - політика використання даних API: чи використовуються дані для тренування та які доступні параметри приватності.

#### Посилання на інструменти та провайдери

- [OpenAI](https://openai.com/) - провайдер моделей GPT; API для тексту/візуальних задач, enterprise‑опції приватності.
- [Anthropic Claude](https://www.anthropic.com/claude) - лінійка моделей Claude з фокусом на безпеку та міркування.
- [Google Gemini](https://ai.google.dev/) - сімейство моделей Gemini; доступ через Gemini API та Vertex AI.
- [xAI (Grok)](https://x.ai/) - провайдер моделі Grok; API для текстових задач.
- [Copilot для Microsoft 365](https://www.microsoft.com/microsoft-copilot) - асистент у додатках Microsoft 365 із доступом до даних організації та корпоративними контролями.
- [GitHub Copilot](https://github.com/features/copilot) - асистент коду в IDE/CLI, чат і автодоповнення; варіанти для підприємств.
- [Cursor](https://www.cursor.com/) - IDE з глибокою інтеграцією LLM та агентним робочим процесом.
- [Windsurf](https://codeium.com/windsurf) - AI‑first IDE від Codeium.
- [OpenRouter](https://openrouter.ai/) - агрегатор моделей із єдиним API та білінгом.
- [Atlassian Rovo](https://www.atlassian.com/software/rovo) - вбудований асистент у Jira/Confluence для пошуку, узагальнення та генерації.
- [Fireflies](https://fireflies.ai/) - транскрибування та сумаризація зустрічей з інтеграціями.

### Підсумок

Потенціал LLM для розробки дуже великий. Єдиної "ідеальної" методології поки немає, але окремі елементи вже час системно впроваджувати. Епоха, коли ці інструменти були іграшками, - завершилась, і період, коли їх використання було радше опцією, стрімко добігає кінця.


