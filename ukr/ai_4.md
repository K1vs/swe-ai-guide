### 4. Від чату до агентів: від чудес до практики

Хоч і час чудес поки закінчився, але почався час практичного застосування. ЛЛМ за декілька стрибків застрибнули у зону великої практичної корисності й далі рухаються рівномірно. Проте для реальної віддачі простого чату зазвичай мало. 

Є фундаментальні обмеження, які поки далекі від повного розв'язання: довготривала пам'ять і розмір контексту. Це не лише питання обчислювальних ресурсів, а й математичної складності. Механізм уваги масштабується погано, інформація розмивається, а "контекст роутінг" (вибір релевантної інформації з великого обсягу даних) стає критичним. Дозволений обсяг контексту - компромісна величина для кожної моделі. Просте збільшення вікна не усуває проблему, а лише дає моделі "не впасти". Якість відповіді й швидкість при цьому деградують, вартість росте, а помилки накопичуються.

#### Поточні фундаментальні обмеження

- **Розмір контексту і складність уваги**: базовий механізм уваги має квадратичну складність від довжини послідовності (O(n^2)). Навіть із оптимізаціями пропускна здатність і латентність погіршуються при зростанні вікна. Розширення контексту - це компроміс: модель "не падає", але якість резонування, стабільність і швидкість деградують, а вартість інференсу (обчислення відповіді моделлю) зростає непропорційно.
- **Розмивання і релевантність інформації**: у великому вікні релевантні фрагменти губляться серед шуму. Модель схильна до "позиційних" і "новинних" зміщень (надає більше ваги останній або першій інформації), переоцінює останні підказки й недооцінює ранні. Тому потрібні механізми відбору - контекст роутінг і вибірка знань, але вони мають власні похибки (хибні спрацьовування/пропуски - можуть вибрати неважливе або пропустити важливе).
- **Довготривала пам’ять як зовнішній стан**: чиста ЛЛМ не має стійкої пам’яті між сесіями. Будь-яка "пам’ять" вимагає зовнішніх сховищ (бази даних, вектори, нотатки) і політик доступу. Проблеми: адресація (як знайти потрібне), релевантність (що саме підвантажити), консистентність (як оновлювати без конфліктів) і приватність.
- **Деградація на довгих ланцюжках міркувань**: помилки накопичуються каскадно. Навіть зі step-by-step промтингом (покроковими інструкціями) зростає ризик дрейфу інструкцій, втрати проміжних припущень і суперечностей між кроками. Позиційне кодування (спосіб запам'ятовування порядку слів) й обмеженість внутрішнього стану не гарантують надійного "трасування" довгих доведень.
- **Відтворюваність і чутливість до контексту**: стохастична природа семплінгу (випадковість при виборі слів) й висока чутливість до формулювань призводять до варіативних відповідей. Невеликі зміни в порядку чи формі фактів дають різні висновки; повна детермінізація часто веде до падіння якості ("mode collapse" - зациклювання на однотипних відповідях).
- **Вартість і латентність**: довгі контексти і великі моделі вимагають значних обчислювальних ресурсів (пам’ять, пропускна здатність, час). Це обмежує інтерактивні сценарії й масштабування в проді, змушуючи балансувати між якістю, швидкістю та ціною.

#### Використання лише чату висвітлює типові труднощі:

- **Встановлення контексту**: складно структуровано підвантажити великий матеріал, підтримувати актуальність і релевантність фактів.
- **Високі вимоги до промтингу**: потрібно вміти чітко формулювати інструкції, будувати ланцюжки підказок, контролювати стиль і формат результату.
- **Застосування результату**: інтеграція відповідей у робочі артефакти (код, документи, дані) часто ручна, клопітка і помилкова.
- **Збереження напрацювань**: потрібні механізми для пам’яті - установчі запити, персональні уподобання, робочі контексти, повторне використання промтів.
- **Відтворюваність і контроль**: без інструментів перевірки та журналювання важко гарантувати стабільність процесу і якість підсумку.

Звідси природно виростає поняття **LLM-агента**. Агент - це не просто чат, а система, що ставить підзадачі, планує кроки, викликає інструменти (пам'ять, файлову систему, репозиторії, виконавче оточення), оцінює проміжні результати й коригує хід роботи. 

Ключові властивості агента: декомпозиція задачі, використання інструментів, ітеративна перевірка, стійкий стан/пам'ять, а також керований контекст роутінг (відбір потрібної інформації) і вибірка знань під задачу. 

Завдання агента - не "згенерувати відповідь на промт", а організувати виконання процесу з обмеженнями, критеріями приймання і перевірками.

Ось приклад у програмуванні, де агент значно потужніший за чат: міграція коду під нову версію фреймворку в монорепозиторії. Агент:
1) сканує репо, будує план міграції;
2) знаходить локації, де змінюються API;
3) робить локальні правки серіями, запускає тести й лінтери;
4) збирає лог помилок, уточнює план;
5) оновлює документацію та формує pull request з чітким дифом.
Звичайний чат видасть фрагменти коду або поради, але не проведе повний цикл "план → зміни → перевірка → звіт".

Або ось інший приклад - усунення флакі-тесту (нестабільного тесту, що іноді падає без причини). Агент здатен автоматично відтворити баг, варіювати середовище, зібрати артефакти (логи, трейсінги), запропонувати патч, прогнати тести в матриці конфігурацій і підготувати короткий звіт причинно-наслідкових зв'язків. 

Тут ключова сила агента - у керуванні інструментами, пам'яті й циклах зворотного зв'язку, що виходять за межі "однієї відповіді" чату. 

Більш детально про агенти розповім в наступному пості.



#### Що почитати далі

- [Retrieval-Augmented Generation for Knowledge-Intensive NLP (2020)](https://arxiv.org/abs/2005.11401) - базова робота про RAG: поєднання пошуку та генерації.
- [A Survey on Retrieval-Augmented Generation (2023)](https://arxiv.org/abs/2312.10997) - огляд підходів до RAG, індексації, оновлення знань та оцінювання.
- [ReAct: Synergizing Reasoning and Acting in Language Models (2022)](https://arxiv.org/abs/2210.03629) - шаблон поєднання міркування з викликом інструментів.
- [Toolformer: Language Models Can Teach Themselves to Use Tools (2023)](https://arxiv.org/abs/2302.04761) - як навчати моделі виклику зовнішніх інструментів.
- [Reflexion: Language Agents with Verbal Reinforcement Learning (2023)](https://arxiv.org/abs/2303.11366) - самокорекція та пам’ять у агентів.
- [LLM-based Agents: A Survey (2023)](https://arxiv.org/abs/2308.11432) - огляд архітектур агентів, планування, пам’яті та використання інструментів.

